{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Word Embedding Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The U.S. Patent Office releases the full text of all patents from 1976 to present on their website, USPTO Open Data. \n",
    "\n",
    "In this notebook, [a subset of that data](https://developer.uspto.gov/product/patent-grant-full-text-dataxml), from Jan 2022 to Jun 2022, will be used to train custom word embedding vectors using gensim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import html\n",
    "import re\n",
    "import os\n",
    "\n",
    "from contractions import CONTRACTION_MAP\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "\n",
    "from gensim.models import Word2Vec, Phrases, FastText\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = WordNetLemmatizer()\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def expand_contractions(text, contraction_mapping=CONTRACTION_MAP):\n",
    "    \n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())), \n",
    "                                      flags=re.IGNORECASE|re.DOTALL)\n",
    "    def expand_match(contraction):\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = contraction_mapping.get(match)               \n",
    "        expanded_contraction = first_char+expanded_contraction[1:]\n",
    "        return expanded_contraction\n",
    "        \n",
    "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
    "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "    return expanded_text\n",
    "\n",
    "\n",
    "def remove_newline_characters(text):\n",
    "    pattern = r'[\\r\\n]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_special_characters(text, remove_digits=False):\n",
    "    pattern = r'[^a-zA-z0-9\\s]' if not remove_digits else r'[^a-zA-z\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def lemmatize(text):\n",
    "    return lm.lemmatize(text)\n",
    "\n",
    "\n",
    "def stem(text):\n",
    "    return ps.stem(text)\n",
    "\n",
    "\n",
    "def normalize_corpus(corpus, method='lem'):\n",
    "    corpus = corpus.lower()\n",
    "    corpus = remove_newline_characters(corpus)\n",
    "    corpus = expand_contractions(corpus, contraction_mapping=CONTRACTION_MAP)\n",
    "\n",
    "    sents = sent_tokenize(corpus)\n",
    "    norm_corpus = []\n",
    "\n",
    "    for sent in sents:\n",
    "        sent = remove_special_characters(sent)\n",
    "\n",
    "        words = word_tokenize(sent)\n",
    "\n",
    "        if method == 'lem':\n",
    "            norm_words = [lemmatize(word) for word in words if word not in stopwords.words('english')]\n",
    "        else:\n",
    "            norm_words = [stem(word) for word in words if word not in stopwords.words('english')]\n",
    "\n",
    "        norm_corpus.append(' '.join(norm_words))\n",
    "\n",
    "    return norm_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load & Parse Patents Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ipg220614.xml\n",
      "Extracted text from 2000 patents..\n",
      "Extracted text from 4000 patents..\n",
      "Extracted text from 6000 patents..\n",
      "Total Patents: 7463\n",
      "\n",
      "Processing file: ipg220412.xml\n",
      "Extracted text from 2000 patents..\n",
      "Extracted text from 4000 patents..\n",
      "Extracted text from 6000 patents..\n",
      "Total Patents: 7399\n",
      "\n",
      "Processing file: ipg220201.xml\n",
      "Extracted text from 2000 patents..\n",
      "Extracted text from 4000 patents..\n",
      "Extracted text from 6000 patents..\n",
      "Total Patents: 7395\n",
      "\n",
      "Processing file: ipg220215.xml\n",
      "Extracted text from 2000 patents..\n",
      "Extracted text from 4000 patents..\n",
      "Extracted text from 6000 patents..\n",
      "Total Patents: 7313\n",
      "\n",
      "Processing file: ipg220405.xml\n",
      "Extracted text from 2000 patents..\n",
      "Extracted text from 4000 patents..\n",
      "Extracted text from 6000 patents..\n",
      "Total Patents: 7373\n",
      "\n",
      "Processing file: ipg220607.xml\n",
      "Extracted text from 2000 patents..\n",
      "Extracted text from 4000 patents..\n",
      "Extracted text from 6000 patents..\n",
      "Total Patents: 7461\n",
      "\n",
      "Processing file: ipg220503.xml\n",
      "Extracted text from 2000 patents..\n",
      "Extracted text from 4000 patents..\n",
      "Extracted text from 6000 patents..\n",
      "Total Patents: 7429\n",
      "\n",
      "Processing file: ipg220517.xml\n",
      "Extracted text from 2000 patents..\n",
      "Extracted text from 4000 patents..\n",
      "Extracted text from 6000 patents..\n",
      "Total Patents: 7453\n",
      "\n",
      "Processing file: ipg220104.xml\n",
      "Extracted text from 2000 patents..\n",
      "Extracted text from 4000 patents..\n",
      "Extracted text from 6000 patents..\n",
      "Total Patents: 6939\n",
      "\n",
      "Processing file: ipg220111.xml\n",
      "Extracted text from 2000 patents..\n",
      "Extracted text from 4000 patents..\n",
      "Total Patents: 5679\n",
      "\n",
      "Processing file: ipg220510.xml\n",
      "Extracted text from 2000 patents..\n",
      "Extracted text from 4000 patents..\n",
      "Extracted text from 6000 patents..\n",
      "Total Patents: 7416\n",
      "\n",
      "Processing file: ipg220301.xml\n",
      "Extracted text from 2000 patents..\n",
      "Extracted text from 4000 patents..\n",
      "Extracted text from 6000 patents..\n",
      "Total Patents: 7356\n",
      "\n",
      "Processing file: ipg220315.xml\n",
      "Extracted text from 2000 patents..\n",
      "Extracted text from 4000 patents..\n",
      "Total Patents: 5951\n",
      "\n",
      "Processing file: ipg220329.xml\n",
      "Extracted text from 2000 patents..\n",
      "Extracted text from 4000 patents..\n",
      "Extracted text from 6000 patents..\n",
      "Total Patents: 7339\n",
      "\n",
      "Processing file: ipg220125.xml\n",
      "Extracted text from 2000 patents..\n",
      "Extracted text from 4000 patents..\n",
      "Total Patents: 5865\n",
      "\n",
      "Processing file: ipg220118.xml\n",
      "Extracted text from 2000 patents..\n",
      "Extracted text from 4000 patents..\n",
      "Total Patents: 5631\n",
      "\n",
      "Processing file: ipg220322.xml\n",
      "Extracted text from 2000 patents..\n",
      "Extracted text from 4000 patents..\n",
      "Extracted text from 6000 patents..\n",
      "Total Patents: 7352\n",
      "\n",
      "Processing file: ipg220524.xml\n",
      "Extracted text from 2000 patents..\n",
      "Extracted text from 4000 patents..\n",
      "Extracted text from 6000 patents..\n",
      "Total Patents: 7436\n",
      "\n",
      "Processing file: ipg220531.xml\n",
      "Extracted text from 2000 patents..\n",
      "Extracted text from 4000 patents..\n",
      "Extracted text from 6000 patents..\n",
      "Total Patents: 7424\n",
      "\n",
      "Processing file: ipg220308.xml\n",
      "Extracted text from 2000 patents..\n",
      "Extracted text from 4000 patents..\n",
      "Extracted text from 6000 patents..\n",
      "Total Patents: 7402\n",
      "\n",
      "Processing file: ipg220208.xml\n",
      "Extracted text from 2000 patents..\n",
      "Extracted text from 4000 patents..\n",
      "Total Patents: 5888\n",
      "\n",
      "Processing file: ipg220426.xml\n",
      "Extracted text from 2000 patents..\n",
      "Extracted text from 4000 patents..\n",
      "Extracted text from 6000 patents..\n",
      "Total Patents: 7336\n",
      "\n",
      "Processing file: ipg220222.xml\n",
      "Extracted text from 2000 patents..\n",
      "Extracted text from 4000 patents..\n",
      "Extracted text from 6000 patents..\n",
      "Total Patents: 7362\n",
      "\n",
      "Processing file: ipg220419.xml\n",
      "Extracted text from 2000 patents..\n",
      "Extracted text from 4000 patents..\n",
      "Extracted text from 6000 patents..\n",
      "Total Patents: 7427\n",
      "\n",
      "CPU times: user 23h 21min 57s, sys: 3h 11min 26s, total: 1d 2h 33min 24s\n",
      "Wall time: 1d 2h 33min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_dir = r'./data/'\n",
    "\n",
    "with open('./data/training_corpus.txt', 'w') as f, open('./data/errors.txt', 'w') as err:\n",
    "    for file in os.listdir(data_dir):\n",
    "        if '.xml' in file:\n",
    "            print('Processing file: %s' % file)\n",
    "            \n",
    "            patents = html.unescape(open(os.path.join(data_dir, file), 'r').read())\n",
    "\n",
    "            titles = []\n",
    "            abstracts = []\n",
    "            descriptions = []\n",
    "            \n",
    "            for ind, patent in enumerate(patents.split(r'<?xml version=\"1.0\" encoding=\"UTF-8\"?>')):\n",
    "                try:\n",
    "                    bs = BeautifulSoup(patent)\n",
    "                except:\n",
    "                    err.writelines(patent + '\\n')\n",
    "\n",
    "                try:\n",
    "                    titles.append([elm.text for elm in bs.find_all('invention-title')])\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                try:\n",
    "                    abstracts.append([elm.text for elm in bs.find_all('abstract')])\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                try:\n",
    "                    descriptions.append([elm.text for elm in bs.find_all('description')])\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "                if (ind+1) % 2000 == 0:\n",
    "                    print('Extracted text from %i patents..' % (ind+1))\n",
    "\n",
    "            print('Total Patents: %i' % ind)\n",
    "            print()\n",
    "\n",
    "            for ind, item in enumerate(titles + abstracts + descriptions):\n",
    "                if item:\n",
    "                    norm_corpus = normalize_corpus(item[0], method='lem')\n",
    "                    f.writelines('%s\\n' % item for item in norm_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterator / Generator - Full Subset\n",
    "\n",
    "Solution courtesy of [this post](https://stackoverflow.com/questions/56468865/sentence-iterator-to-pass-to-gensim-language-model)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_generator(training_corpus_file, min_len=5):\n",
    "    with open(training_corpus_file, 'r') as f:\n",
    "        for line in f:\n",
    "            if len(line.split(' ')) >= min_len:\n",
    "                yield line[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentencesIterator():\n",
    "    def __init__(self, generator_function, dir, min_len):\n",
    "        self.generator_function = generator_function\n",
    "        self.dir = dir\n",
    "        self.min_len = min_len\n",
    "\n",
    "        self.generator = self.generator_function(self.dir, self.min_len)\n",
    "\n",
    "    def __iter__(self):\n",
    "        # reset the generator\n",
    "        self.generator = self.generator_function(self.dir, self.min_len)\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        result = next(self.generator)\n",
    "        if result is None:\n",
    "            raise StopIteration\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec Model (gensim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2h 35min 25s, sys: 1min 41s, total: 2h 37min 6s\n",
      "Wall time: 1h 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "corpus = SentencesIterator(tokens_generator, dir=r'./data/training_corpus.txt', min_len=5)\n",
    "\n",
    "model = Word2Vec(sentences=corpus, vector_size=100, window=5, min_count=1, epochs=4)\n",
    "model.save(r'./models/patents-2022-w2v.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = SentencesIterator(tokens_generator, dir=r'./data/training_corpus.txt', min_len=5)\n",
    "\n",
    "model = FastText(sentences=corpus, vector_size=100, window=5, min_count=1, epochs=4)\n",
    "model.save(r'./models/patents-2022-fasttext.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = SentencesIterator(tokens_generator, dir=r'./data/training_corpus.txt', min_len=5)\n",
    "bigram_transformer = Phrases(corpus)\n",
    "\n",
    "model = Word2Vec(sentences=bigram_transformer[corpus], vector_size=100, window=5, min_count=1, epochs=4)\n",
    "model.save(r'./models/patents-2022-w2v-ngram.model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "48d39e6237c53a792bc3d9d6b208352e55e343682fa024294b0ea54c5b55a601"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
